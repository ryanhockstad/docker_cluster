input {
  file {
    id => "custom_file_plugin"
    path => "/usr/share/logstash/logs/*.log"
    sincedb_path => "/usr/share/logstash/logs/sincedb"
    start_position => "beginning"
  }
}

filter {
  csv {
    separator => ","
    skip_header => "false"
    columns => [ "column1", "timey", "column2", "column3",  "panw.panos.sub_type", "column4", "column5", "client.ip"]
  }
  date {
    target => "@timestamp"
    match => ["timey", "yyyy/MM/dd HH:mm:ss"]
  }
  mutate {
    add_field => { "custom_field" => "custom_datastream" }
    rename => { "panw.panos.sub_type" => "[panw][panos][sub_type]" }
    rename => { "client.ip" => "[client][ip]" }
  }
  prune {
    blacklist_names => ["column*", "timey"]
  }
}

output {
  elasticsearch {
    hosts => ["https://node-1", "https://node-2"]
    ssl => true
    cacert => '/usr/share/elasticsearch/config/certs/ca/ca.crt' # maybe use keystore for this 
    keystore => '${CERTS_DIR}/logstash/logstash_key.jks'
    keystore_password => "${LOG_PASS}"
    manage_template => false
    index => logstash
    user => "elastic"
    password => "changeme" # TODO: use keystore
    ilm_enabled => true
    ilm_pattern => "000001"
    ilm_policy => example
    ilm_rollover_alias => logstash_panos
  }
}